{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmHnC2uYycsl",
        "outputId": "763fdbe1-bda2-4fe9-d3e0-d574d8432d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.44)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.52.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.17)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.115.4)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.27.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.35)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.32.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.10)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.41.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->tavily-python) (1.2.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (75.1.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Install important Python libraries\n",
        "\n",
        "  !pip install langchain langchain-openai langchain-community langchain-chroma tavily-python langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS7t63EpztZA"
      },
      "source": [
        "**Setting API Keys**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3vUgLj1qzwKY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '' # add open api key here,  OpenAI for LLMs\n",
        "#os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"\" # addr tavily key here, Tavily for doing web search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MivrMuvJpMk3"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):  # A TypedDict called GraphState is created.\n",
        "    question: str\n",
        "    documents: List[str]\n",
        "    generation: str   #LLM generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-IjjURjz4Q-"
      },
      "source": [
        "**Route---router_chain and related function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbLJML1AgZfh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# System Prompt\n",
        "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
        "   if the question is related to Viswanathan or chess, answer 'vectorstore'. Otherwise, answer 'web'.\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system),\n",
        "     (\"human\", \"{question}\")])\n",
        "# Combines the system instruction and user's question dynamically to create a full prompt for the LLM.\n",
        "llm = ChatOpenAI()\n",
        "router_chain = route_prompt | llm\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def route_question(state):\n",
        "    question = state[\"question\"] #Taking the current state where the user's question is stored\n",
        "    source = router_chain.invoke({\"question\": question}) # Pass the question to the router_chain\n",
        "    if source.content == \"web\":\n",
        "       return \"web_search\"\n",
        "    elif source.content == \"vectorstore\":\n",
        "       return \"vectorstore\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRQcZHUqCfpl"
      },
      "source": [
        "**RAG_chain: used for generation in both web and vectorstore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tWql5xhCrp-",
        "outputId": "6c40418c-f712-47bd-904f-8b16d26b2df1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "rag_chain = prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLl9jwrAo7o"
      },
      "source": [
        "**The branch of web search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqEAZtog1Ub4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)\n",
        "\n",
        "def web_search(state):\n",
        "    print(\"-----This is for web search------\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "\n",
        "    return {\"documents\": web_results, \"question\": question}\n",
        "\n",
        "#the generation part for web branch\n",
        "\n",
        "def generate_web(state):\n",
        "\n",
        "    print(\"-------generation of web------\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw-bsYZZ1dCb"
      },
      "source": [
        "**The branch of vectorstore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mGWe_-21fFU"
      },
      "outputs": [],
      "source": [
        "# creating internal database\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.schema import Document\n",
        "\n",
        "loader = TextLoader('/content/Vishva.txt')\n",
        "\n",
        "data=loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=300)\n",
        "docs = text_splitter.split_documents(data) # split document into smaller pieces (manageable chunks)\n",
        "\n",
        "#  create embeddings using OpenAI, Store them into a Chroma vectorstore, Make a retriever for searching later\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(docs,embedding=embedding)\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "def retrieve(state):\n",
        "    print(\"------This is for vectorstore---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZJ9KrJI1oG6"
      },
      "source": [
        "**Vectorstore branch -- Grade part(used for checking relevance)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aeSKJsj2FNn"
      },
      "outputs": [],
      "source": [
        "#chain to check if retrieved documents are relevant\n",
        "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    If the document is relevent, answer 'yes'; if the document is not relevent, answer 'no'.\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system),\n",
        "     (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "grade_chain = grade_prompt | llm\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#function\n",
        "def grade_documents(state):\n",
        "   # print(\"--------checking relevance----------\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    related_docs = []\n",
        "    for d in documents:\n",
        "        result = grade_chain.invoke({\"question\": question, \"document\": d.page_content})\n",
        "        if result.content == \"Yes\":\n",
        "            related_docs.append(d)\n",
        "        else:\n",
        "            continue\n",
        "    return {\"documents\": related_docs, \"question\": question}\n",
        "#------------------------------------------------------------------------\n",
        "#if there is relevant docs after checking, we can generate\n",
        "def decide_to_generate(state):\n",
        "    state[\"question\"]\n",
        "    related_documents = state[\"documents\"]\n",
        "\n",
        "    if not related_documents:\n",
        "        return \"rewrite_question\"\n",
        "    else:\n",
        "        return \"generate\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2flpTvZFhZt"
      },
      "source": [
        "**Vectorstore branch -- rewriting query **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYjE9Lgo3q3Z"
      },
      "outputs": [],
      "source": [
        "#chain\n",
        "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "     for vectorstore retrieval. If the question is about Viswanathan's achievement and the year is not 2007,  rewrite the year to 2007.\"\"\"\n",
        "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system),\n",
        "     (\"human\",\n",
        "      \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",),\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "#function\n",
        "def rewrite_question(state):\n",
        "    print(\"---------rewrite the question---------\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    better_question = rewrite_chain.invoke({\"question\": question})\n",
        "    print(\"I can't find the relevent record of this year, so I will rewrite to another year\")\n",
        "    print(better_question)\n",
        "    return {\"documents\": documents, \"question\": better_question}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u9v8cjN2V8v"
      },
      "source": [
        "**Vectorstore branch -- Generation part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87R3pfc92YIU"
      },
      "outputs": [],
      "source": [
        "def generate_vectorstore(state):\n",
        "  #  print(\"------generate for vectorstore---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiIj-4K32iU0"
      },
      "source": [
        "**Vectorstore branch -- Hallucination part(checking hallucination)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8RE5MnW2kw_"
      },
      "outputs": [],
      "source": [
        "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "       answer 'yes' or 'no'. 'yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system),\n",
        "     (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "hallucination_chain = hallucination_prompt | llm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXYinLUP33Nu"
      },
      "source": [
        "**Vectorstore branch--final decision part(give the final decision of \"anwser\" or \"rewrite\")**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MB14VSI35P8"
      },
      "outputs": [],
      "source": [
        "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
        "     Give an answer 'yes' or 'no'. 'yes' means that the answer resolves the question.\"\"\"\n",
        "final_decision_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system),\n",
        "     (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ])\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "final_decision_chain = final_decision_prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pJ3UPzS3-qw"
      },
      "outputs": [],
      "source": [
        "def check_hallucination_and_grade_answer(state): # state as input â€” a dictionary containing:question, documents , generation\n",
        "   # print(\"------checking hallucination---\")\n",
        "   # Save the question, documents, and generation separately so we can work with them easily.\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    score1 = hallucination_chain.invoke({\"documents\": documents, \"generation\": generation}) # The AI model checks:\"Is the answer properly supported by the facts in the documents?\"\n",
        "\n",
        "    if score1.content == \"Yes\":\n",
        "      #  print(\"-------no hallucination---------\")\n",
        "        score2 = final_decision_chain.invoke({\"question\": question, \"generation\": generation}) # Ask:\"Does the generated answer properly resolve the user's original question?\"\n",
        "        if score2.content == \"yes\":\n",
        "           # print(\"------we can output the final answer-------\")\n",
        "            return \"solved\"\n",
        "        else:\n",
        "           # print(\"-----we can't output the answer, need to rewrite-----\")\n",
        "            return \"not solved\"\n",
        "    else:\n",
        "       # print(\"-----There is hallucination------\")\n",
        "        return \"not supported\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b94rilzt4AwD"
      },
      "source": [
        "**Build graph**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPcGJJANv1GV"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"web_search\", web_search)\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\"grade_documents\", grade_documents)\n",
        "workflow.add_node(\"generate_vectorstore\", generate_vectorstore)\n",
        "workflow.add_node(\"generate_web\", generate_web)\n",
        "workflow.add_node(\"rewrite_question\", rewrite_question)\n",
        "\n",
        "# Add edges\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"web_search\", \"generate_web\")\n",
        "workflow.add_edge(\"generate_web\", END)\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"rewrite_question\": \"rewrite_question\",\n",
        "        \"generate\": \"generate_vectorstore\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"rewrite_question\", \"retrieve\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate_vectorstore\",\n",
        "    check_hallucination_and_grade_answer,\n",
        "    {\n",
        "        \"not supported\": \"generate_vectorstore\",\n",
        "        \"solved\": END,\n",
        "        \"not solved\": \"rewrite_question\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ2k5tyrIgE9"
      },
      "source": [
        "**Test case1--irrelevent and rewrite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA81UvfK3lCV",
        "outputId": "bd089939-d8ae-4bcb-c3ec-b7231f980846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------This is for vectorstore---\n",
            "\"Node 'retrieve':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'generate_vectorstore':\"\n",
            "'\\n---\\n'\n",
            "---------rewrite the question---------\n",
            "I can't find the relevent record of this year, so I will rewrite to another year\n",
            "Tell me about Viswanathan's achievement in 2007.\n",
            "\"Node 'rewrite_question':\"\n",
            "'\\n---\\n'\n",
            "------This is for vectorstore---\n",
            "\"Node 'retrieve':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'generate_vectorstore':\"\n",
            "'\\n---\\n'\n",
            "('In 2007, Viswanathan Anand achieved the title of World Chess Champion. '\n",
            " \"Anand's success marked a significant milestone in his illustrious career as \"\n",
            " 'a chess Grandmaster. His victory in 2007 further solidified his reputation '\n",
            " 'as one of the greatest chess players of all time.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "input1 = {\n",
        "    \"question\": \"tell me about Viswanathan's achievement in 2003?\"\n",
        "}\n",
        "for output in app.stream(input1):\n",
        "    for key, value in output.items():\n",
        "       pprint(f\"Node '{key}':\")\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "pprint(value[\"generation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkTCE6PYI89t"
      },
      "source": [
        "**Test case2--relevent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfO4KvrxyR97",
        "outputId": "fd6f1675-9fcc-43d3-be3b-4e72ec4588c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------This is for vectorstore---\n",
            "\"Node 'retrieve':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'generate_vectorstore':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'generate_vectorstore':\"\n",
            "'\\n---\\n'\n",
            "\"Node 'generate_vectorstore':\"\n",
            "'\\n---\\n'\n",
            "('Viswanathan Anand is a celebrated Indian chess Grandmaster and former World '\n",
            " \"Chess Champion. He became India's first chess Grandmaster at the age of 18, \"\n",
            " 'bringing global attention to Indian chess. Anand quickly made his mark on '\n",
            " 'the chess scene with his speed and accuracy, earning the nickname \"Lightning '\n",
            " 'Kid.\"')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "input2 = {\n",
        "    \"question\": \"tell me about Viswanathan's achievements?\"\n",
        "}\n",
        "for output in app.stream(input2):\n",
        "  for key, value in output.items():\n",
        "    pprint(f\"Node '{key}':\")\n",
        "  pprint(\"\\n---\\n\")\n",
        "\n",
        "# Print generation\n",
        "pprint(value[\"generation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_X1lOOGJTA5"
      },
      "source": [
        "**Test case3--web**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSyED0u2xVqM",
        "outputId": "f4ac1500-7b65-481c-8dd2-736fe0873d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----This is for web search------\n",
            "\"Node 'web_search':\"\n",
            "'\\n---\\n'\n",
            "-------generation of web------\n",
            "\"Node 'generate_web':\"\n",
            "'\\n---\\n'\n",
            "('Recent baseball events include J.D. Martinez signing a one-year deal with '\n",
            " 'the Mets and reigning NL Cy Young Blake Snell signing with the Giants. '\n",
            " 'Shohei Ohtani declined to comment on an interpreter scandal, and the '\n",
            " \"Dodgers' Mookie Betts hit his first home run of the 2024 season. Gunnar \"\n",
            " 'Henderson is back and ready to ramp up for the season in Sarasota.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "input3 = {\n",
        "    \"question\": \"tell me about recent baseball's events?\"\n",
        "}\n",
        "for output in app.stream(input3):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"Node '{key}':\")\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Print generation\n",
        "pprint(value[\"generation\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}